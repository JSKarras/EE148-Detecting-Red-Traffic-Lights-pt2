{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Jupyter Notebook for running all of homework 2. '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Jupyter Notebook for running all of homework 2. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Import modules and libraries'''\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Split data into training and testing datasets. '''\n",
    "np.random.seed(2020) # to ensure you always get the same train/test split\n",
    "\n",
    "data_path = '/Users/Johanna/Desktop/Computer Vision/hw01/RedLights2011_Medium'\n",
    "gts_path = '../data/hw02_annotations/'\n",
    "split_path = '../data/hw02_splits/'\n",
    "preds_path = '../data/hw02_predictions/'\n",
    "os.makedirs(preds_path, exist_ok=True) # create directory if needed\n",
    "\n",
    "split_test = True # False splits filenames only, True splits images into separate files\n",
    "train_frac = 0.85\n",
    "\n",
    "# get sorted list of files:\n",
    "file_names = sorted(os.listdir(data_path))\n",
    "# remove any non-JPEG files:\n",
    "file_names = [f for f in file_names if '.jpg' in f]\n",
    "# split file names into train and test\n",
    "file_names_train = []\n",
    "file_names_test = []\n",
    "\n",
    "'''\n",
    "My code below. \n",
    "'''\n",
    "file_names_train = np.random.choice(file_names, int(len(file_names)*0.85), replace=False)\n",
    "file_names_test = [f for f in file_names if f not in file_names_train]\n",
    "\n",
    "'''\n",
    "My code above. \n",
    "'''\n",
    "\n",
    "assert (len(file_names_train) + len(file_names_test)) == len(file_names)\n",
    "assert len(np.intersect1d(file_names_train,file_names_test)) == 0\n",
    "\n",
    "np.save(os.path.join(split_path,'file_names_train.npy'),file_names_train)\n",
    "np.save(os.path.join(split_path,'file_names_test.npy'),file_names_test)\n",
    "\n",
    "if split_test:\n",
    "    with open(os.path.join(gts_path, 'annotations.json'),'r') as f:\n",
    "        gts = json.load(f)\n",
    "    \n",
    "    # Use file_names_train and file_names_test to apply the split to the\n",
    "    # annotations\n",
    "    gts_train = {}\n",
    "    gts_test = {}\n",
    "    \n",
    "    '''\n",
    "    My code below. \n",
    "    '''\n",
    "    for filename in file_names_train:\n",
    "        gts_train[filename] = gts[filename]\n",
    "    for filename in file_names_test:\n",
    "        gts_test[filename] = gts[filename]\n",
    "\n",
    "    '''\n",
    "    My code above. \n",
    "    '''\n",
    "    \n",
    "    with open(os.path.join(gts_path, 'annotations_train.json'),'w') as f:\n",
    "        json.dump(gts_train,f)\n",
    "\n",
    "    with open(os.path.join(gts_path, 'annotations_test.json'),'w') as f:\n",
    "        json.dump(gts_test,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Helper functions for running predictions. '''\n",
    "def compute_convolution(I, T, stride=1, window_size=None, padding=None):\n",
    "    '''\n",
    "    This function takes an image <I> and a template <T> (both numpy arrays) \n",
    "    and returns a heatmap where each grid represents the output produced by \n",
    "    convolution at each location. You can add optional parameters (e.g. stride, \n",
    "    window_size, padding) to create additional functionality. \n",
    "    '''\n",
    "    (n_rows, n_cols, n_channels) = np.shape(I)\n",
    "    \n",
    "    '''\n",
    "    BEGIN YOUR CODE\n",
    "    '''\n",
    "    # Get shape of template\n",
    "    (t_rows, t_cols, t_channels) = np.shape(T)\n",
    "    \n",
    "    # Add padding to preserve shape of image\n",
    "    x_pad, y_pad = t_rows-1, t_cols-1\n",
    "    I = np.pad(I, ((x_pad, x_pad), (y_pad, y_pad), (0,0)), 'constant') # ((top, bot),(left,right))\n",
    "    \n",
    "    heatmap = np.zeros((n_rows, n_cols))\n",
    "    for row in range(0, n_rows, stride):\n",
    "        for col in range(0, n_cols, stride):\n",
    "            conv = np.sum(T * I[row:row+t_rows,col:col+t_cols]) / ((t_rows+1)*(t_cols+1)) # * 255\n",
    "            heatmap[row, col] = conv\n",
    "\n",
    "    '''\n",
    "    END YOUR CODE\n",
    "    '''\n",
    "    return heatmap\n",
    "\n",
    "def predict_boxes(I, heatmap, threshold, stride=1, box_size=10):\n",
    "    '''\n",
    "    This function takes heatmap and returns the bounding boxes and associated\n",
    "    confidence scores.\n",
    "    '''\n",
    "\n",
    "    output = []\n",
    "\n",
    "    '''\n",
    "    BEGIN YOUR CODE\n",
    "    '''\n",
    "    (n_rows, n_cols, n_channels) = np.shape(I)\n",
    "    (h_rows, h_cols) = np.shape(heatmap)\n",
    "    \n",
    "    # Compute size of boxes based on image and heatmap\n",
    "    box_height = box_size\n",
    "    box_width = box_size\n",
    "\n",
    "    for row in range(0, h_rows, stride):\n",
    "        for col in range(0, h_cols, stride):\n",
    "            ul_x, ul_y = row, col\n",
    "            br_x, br_y = row + box_height, col + box_width\n",
    "            score = heatmap[row, col]\n",
    "            if score  > threshold:\n",
    "                flag = True\n",
    "                for [x1, y1, x2, y2, s] in output:\n",
    "                    dist1 = np.sqrt((x1-ul_x)**2 + (y1-ul_y)**2)\n",
    "                    dist2 = np.sqrt((x2-ul_x)**2 + (y2-ul_y)**2)\n",
    "                    if dist1 < 20 or dist2 < 20:\n",
    "                        flag = False\n",
    "\n",
    "                if flag:\n",
    "                    output.append([ul_x, ul_y, br_x, br_y, score])\n",
    "\n",
    "                #plt.imshow(I[ul_x:ul_x+box_height,ul_y:ul_y+box_width])\n",
    "                #plt.colorbar()\n",
    "                #plt.show()\n",
    "\n",
    "    '''\n",
    "    END YOUR CODE\n",
    "    '''\n",
    "\n",
    "    return output\n",
    "\n",
    "def normalize_image(img, kernel):\n",
    "    '''\n",
    "    For an image patch or kernel, img, normalize it with respect to each color channel using\n",
    "    the mean of each color channel of the full image, I. Return the normalized img.\n",
    "    '''\n",
    "    img_normalized = img.copy().astype(np.float)\n",
    "    r, g, b = np.mean(kernel[:, :, 0]), np.mean(kernel[:, :, 1]), np.mean(kernel[:, :, 2])\n",
    "    total = np.sum(r+g+b) \n",
    "    img_normalized[:, :, 0] = 3 * np.maximum(np.subtract(img_normalized[:, :, 0], r), 0) / 255\n",
    "    img_normalized[:, :, 1] = 0.1*np.maximum(np.subtract(img_normalized[:, :, 1], g), 0) / 255\n",
    "    img_normalized[:, :, 2] = 0.1*np.maximum(np.subtract(img_normalized[:, :, 2], b), 0) / 255\n",
    "    \n",
    "    return img_normalized \n",
    "\n",
    "def detect_red_light_mf(I, stride=1):\n",
    "    '''\n",
    "    This function takes a numpy array <I> and returns a list <output>.\n",
    "    The length of <output> is the number of bounding boxes predicted for <I>. \n",
    "    Each entry of <output> is a list <[row_TL,col_TL,row_BR,col_BR,score]>. \n",
    "    The first four entries are four integers specifying a bounding box \n",
    "    (the row and column index of the top left corner and the row and column \n",
    "    index of the bottom right corner).\n",
    "    <score> is a confidence score ranging from 0 to 1. \n",
    "\n",
    "    Note that PIL loads images in RGB order, so:\n",
    "    I[:,:,0] is the red channel\n",
    "    I[:,:,1] is the green channel\n",
    "    I[:,:,2] is the blue channel\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    BEGIN YOUR CODE\n",
    "    '''\n",
    "    # You may use multiple stages and combine the results\n",
    "    T = Image.open('kernel.png').convert(mode='RGB') # base kernel\n",
    "    I_normalized = normalize_image(I, np.asarray(T))\n",
    "    I = I_normalized\n",
    "    \n",
    "    output = []\n",
    "    thresholds = [0.264, 0.435, 0.55, 0.6, 0.6, 0.6]\n",
    "    T_sizes = [3, 5, 10, 20, 30, 50]\n",
    "    for i in range(len(T_sizes)):\n",
    "        T_size, threshold = T_sizes[i], thresholds[i]\n",
    "        T_resized = T.copy().resize((T_size, T_size))\n",
    "        T_resized = np.asarray(T_resized)\n",
    "        T_normalized = normalize_image(T_resized, T_resized)\n",
    "        \n",
    "        T_resized = T_normalized\n",
    "    \n",
    "        heatmap = compute_convolution(I, T_resized, stride)\n",
    "        predicted_boxes = predict_boxes(I, heatmap, threshold, stride, T_size)\n",
    "        output.extend(predicted_boxes)\n",
    "\n",
    "    '''\n",
    "    END YOUR CODE\n",
    "    '''\n",
    "\n",
    "    for i in range(len(output)):\n",
    "        assert len(output[i]) == 5\n",
    "        if (output[i][4] < 0.0) or (output[i][4] > 1.0):\n",
    "            print(output[i][4])\n",
    "        \n",
    "        assert (output[i][4] >= 0.0) and (output[i][4] <= 1.0)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "def visualize_bounding_boxes(I, bounding_boxes):\n",
    "    '''\n",
    "    This function takes a numpy image arry <I> and a list of\n",
    "    <bounding_boxes> and displays I with bounding boxes. \n",
    "    Each element of <bounding boxes> is a 4-integer list \n",
    "    specifying the top left and bottom right corners of bounding \n",
    "    boxes contained in the image I. \n",
    "    '''\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.imshow(I)\n",
    "    idx = 0\n",
    "    for [ul_x, ul_y, br_x, br_y, score] in bounding_boxes:\n",
    "        (x, y) = (ul_x, ul_y)\n",
    "        rect = matplotlib.patches.Rectangle((y, x), -abs(ul_x - br_x), -abs(br_y - ul_y),\n",
    "                                 linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        plt.text(y, x, str(round(score, 4)), color='white')\n",
    "        idx += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:  1\n"
     ]
    }
   ],
   "source": [
    "''' Run predictions! '''\n",
    "# Note that you are not allowed to use test data for training.\n",
    "# set the path to the downloaded data:\n",
    "data_path = '/Users/Johanna/Desktop/Computer Vision/hw01/RedLights2011_Medium'\n",
    "\n",
    "# load splits: \n",
    "split_path = '../data/hw02_splits'\n",
    "file_names_train = np.load(os.path.join(split_path,'file_names_train.npy'))\n",
    "file_names_test = np.load(os.path.join(split_path,'file_names_test.npy'))\n",
    "\n",
    "# set a path for saving predictions:\n",
    "preds_path = '../data/hw02_preds'\n",
    "os.makedirs(preds_path, exist_ok=True) # create directory if needed\n",
    "\n",
    "# Set this parameter to True when you're done with algorithm development:\n",
    "done_tweaking = False\n",
    "\n",
    "'''\n",
    "Make predictions on the training set.\n",
    "'''\n",
    "preds_train = {}\n",
    "for i in range(len(file_names_train)):\n",
    "    print(\"Image: \", i+1)\n",
    "    # read image\n",
    "    img = Image.open(os.path.join(data_path,file_names_train[i]))\n",
    "    #img = Image.open('small_image.png').convert('RGB')\n",
    "    img = np.asarray(img)\n",
    "\n",
    "    # detect red lights in image\n",
    "    preds_train[file_names_train[i]] = detect_red_light_mf(img, stride=1)\n",
    "    # show bounding boxes\n",
    "    visualize_bounding_boxes(img, preds_train[file_names_train[i]])\n",
    "    \n",
    "# save preds (overwrites any previous predictions!)\n",
    "with open(os.path.join(preds_path,'preds_train.json'),'w') as f:\n",
    "    json.dump(preds_train,f)\n",
    "\n",
    "if done_tweaking:\n",
    "    '''\n",
    "    Make predictions on the test set. \n",
    "    '''\n",
    "    preds_test = {}\n",
    "    for i in range(len(file_names_test)):\n",
    "\n",
    "        # read image using PIL:\n",
    "        I = Image.open(os.path.join(data_path,file_names_test[i]))\n",
    "        print(I.shape)\n",
    "        # convert to numpy array:\n",
    "        I = np.asarray(I)\n",
    "        \n",
    "        preds_test[file_names_test[i]] = detect_red_light_mf(I)\n",
    "\n",
    "    # save preds (overwrites any previous predictions!)\n",
    "    with open(os.path.join(preds_path,'preds_test.json'),'w') as f:\n",
    "        json.dump(preds_test,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
